{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import pandas as pd\n",
    "import platform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "if platform.system() == 'Windows':\n",
    "    matplotlib.rc('font', family='Malgun Gothic')\n",
    "elif platform.system() == 'Darwin':\n",
    "    matplotlib.rc('font', family='AppleGothic')\n",
    "else:\n",
    "    matplotlib.rc('font', family='NanumGothic')\n",
    "    \n",
    "# tensorflow warning off\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "class Mish(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'Mish'\n",
    "\n",
    "def mish(x):\n",
    "    return x * K.tanh(K.softplus(x))\n",
    "\n",
    "get_custom_objects().update({'mish': Mish(mish)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 묶어서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_data_2.xlsx에서, 누적데이터의 의미가 사라지는 경기 한 두번만 한 데이터는 삭제하여 input_data_3.xlsx 생성함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.read_excel('input_data_3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year       -0.260338\n",
       "경기수        -0.051461\n",
       "누적경기수      -0.028567\n",
       "피장타율        0.019916\n",
       "방어율         0.041487\n",
       "삼진/볼넷      -0.002584\n",
       "피출루율        0.064685\n",
       "피OPS        0.036986\n",
       "9이닝당 삼진수   -0.041129\n",
       "9이닝당 볼넷수    0.044398\n",
       "잔루처리율      -0.047577\n",
       "해당경기 실점     0.762928\n",
       "cOBP        0.366851\n",
       "cSLG        0.438801\n",
       "cOPS        0.433589\n",
       "cBABIP      0.273871\n",
       "KK/BB      -0.147787\n",
       "wOBA        0.436141\n",
       "WLD         0.161506\n",
       "PARK        0.111454\n",
       "BPF         0.180707\n",
       "PPF         0.151780\n",
       "피장타율_       0.162948\n",
       "방어율_        0.164221\n",
       "삼진/볼넷_     -0.075382\n",
       "피출루율_       0.094825\n",
       "피OPS_       0.147830\n",
       "9이닝당삼진수_    0.011909\n",
       "9이닝당볼넷수_    0.066101\n",
       "잔루처리율_     -0.051008\n",
       "RUN         1.000000\n",
       "Name: RUN, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.corr()['RUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_total['9이닝당 삼진수'];del df_total['9이닝당 볼넷수'];del df_total['9이닝당삼진수_'];del df_total['9이닝당볼넷수_']; #삭제 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set=train_test_split(df_total,test_size=0.2,random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 29) (31, 29)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape, test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WLD</th>\n",
       "      <th>PARK</th>\n",
       "      <th>BPF</th>\n",
       "      <th>PPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1002.500000</td>\n",
       "      <td>0.872587</td>\n",
       "      <td>0.878518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>1031.750000</td>\n",
       "      <td>0.871067</td>\n",
       "      <td>0.874504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.858404</td>\n",
       "      <td>0.879156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>1083.000000</td>\n",
       "      <td>0.883018</td>\n",
       "      <td>0.893453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>938.000000</td>\n",
       "      <td>0.831685</td>\n",
       "      <td>0.798610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>964.000000</td>\n",
       "      <td>0.871238</td>\n",
       "      <td>0.869567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>993.600000</td>\n",
       "      <td>0.873733</td>\n",
       "      <td>0.876009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1007.800000</td>\n",
       "      <td>0.854462</td>\n",
       "      <td>0.856262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1028.500000</td>\n",
       "      <td>0.892555</td>\n",
       "      <td>0.896712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>971.333333</td>\n",
       "      <td>0.846949</td>\n",
       "      <td>0.827631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          WLD         PARK       BPF       PPF\n",
       "94   0.400000  1002.500000  0.872587  0.878518\n",
       "179  0.237500  1031.750000  0.871067  0.874504\n",
       "0    0.566667  1000.000000  0.858404  0.879156\n",
       "105  0.475000  1083.000000  0.883018  0.893453\n",
       "87   0.666667   938.000000  0.831685  0.798610\n",
       "..        ...          ...       ...       ...\n",
       "73   0.350000   964.000000  0.871238  0.869567\n",
       "131  0.380000   993.600000  0.873733  0.876009\n",
       "100  0.520000  1007.800000  0.854462  0.856262\n",
       "89   0.650000  1028.500000  0.892555  0.896712\n",
       "183  0.433333   971.333333  0.846949  0.827631\n",
       "\n",
       "[124 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_a1 = train_set.iloc[:, 12:18] # 타자 데이터(train)\n",
    "\n",
    "input_b1 = train_set.iloc[:,4:11] # 선발투수 데이터(train)\n",
    "input_b2 = train_set.iloc[:, 22:28] # 중간계투 데이터(train)\n",
    "\n",
    "input_c1 = train_set.iloc[:, 18:22] # 파크팩터(train)\n",
    "\n",
    "\n",
    "tinput_a1 = test_set.iloc[:, 12:18]# 타자 데이터(train)\n",
    "\n",
    "tinput_b1 = test_set.iloc[:, 4:11]# 선발투수 데이터(train)\n",
    "tinput_b2 =test_set.iloc[:, 22:28]  # 중간계투 데이터(train)\n",
    "\n",
    "tinput_c1 = test_set.iloc[:, 18:22] # 파크팩터(train)\n",
    "input_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a1 = scaler.fit_transform(input_a1)\n",
    "input_b1 = scaler.fit_transform(input_b1)\n",
    "input_b2 = scaler.fit_transform(input_b2)\n",
    "input_c1 = scaler.fit_transform(input_c1)\n",
    "\n",
    "tinput_a1 = scaler.fit_transform(tinput_a1)\n",
    "tinput_b1 = scaler.fit_transform(tinput_b1)\n",
    "tinput_b2 = scaler.fit_transform(tinput_b2)\n",
    "tinput_c1 = scaler.fit_transform(tinput_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = train_set.iloc[:, -1:]\n",
    "y = test_set.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "득점예측은 딥러닝으로 한다. activation은 relu랑 selu,mish 중 가장 높은 정확도를 가지는 것으로 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A1 = tf.keras.layers.Input(shape=[input_a1.shape[1]], name = \"bat_input_1\") # 타자\n",
    "input_B1 = tf.keras.layers.Input(shape=[input_b1.shape[1]], name = \"pit_input_1\") # 선발투수\n",
    "input_B2 = tf.keras.layers.Input(shape=[input_b2.shape[1]], name = \"pit_input_2\") # 중간계투\n",
    "input_C1 = tf.keras.layers.Input(shape=[input_c1.shape[1]], name = \"external_factor\") # 외적 요인\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "hidden_A00 = tf.keras.layers.Dense(256, activation = \"mish\")(input_A1)\n",
    "# drop_A00 = tf.keras.layers.Dropout(0.5)(hidden_A00)\n",
    "\n",
    "hidden_A01 = tf.keras.layers.Dense(64, activation = \"mish\")(hidden_A00)\n",
    "# drop_A01 = tf.keras.layers.Dropout(0.5)(hidden_A01)\n",
    "\n",
    "hidden_A02 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_A01)\n",
    "drop_A02 = tf.keras.layers.Dropout(0.5)(hidden_A02)\n",
    "\n",
    "hidden_A03 = tf.keras.layers.Dense(32, activation = \"mish\")(drop_A02)\n",
    "# drop_A03 = tf.keras.layers.Dropout(0.5)(hidden_A03)\n",
    "\n",
    "hidden_A04 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_A03)\n",
    "drop_A04 = tf.keras.layers.Dropout(0.5)(hidden_A04)\n",
    "\n",
    "hidden_A05 = tf.keras.layers.Dense(32, activation = \"mish\")(drop_A04)\n",
    "# drop_A05 = tf.keras.layers.Dropout(0.5)(hidden_A05)\n",
    "\n",
    "hidden_A06 = tf.keras.layers.Dense(16, activation = \"mish\")(hidden_A05)\n",
    "drop_A06 = tf.keras.layers.Dropout(0.5)(hidden_A06)\n",
    "\n",
    "hidden_A07 = tf.keras.layers.Dense(16, activation = \"mish\")(drop_A06)\n",
    "# hidden_A08 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_A07)\n",
    "# drop_A08 = tf.keras.layers.Dropout(0.5)(hidden_A08)\n",
    "\n",
    "# hidden_A09 = tf.keras.layers.Dense(30, activation = \"mish\")(drop_A08)\n",
    "# hidden_A10 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_A09)\n",
    "# hidden_A11 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_A10)\n",
    "# hidden_A12 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_A11)\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "hidden_B00 = tf.keras.layers.Dense(256, activation = \"mish\")(input_B1)\n",
    "# drop_B00 = tf.keras.layers.Dropout(0.5)(hidden_B00)\n",
    "\n",
    "hidden_B01 = tf.keras.layers.Dense(64, activation = \"mish\")(hidden_B00)\n",
    "# drop_B01 = tf.keras.layers.Dropout(0.5)(hidden_B01)\n",
    "\n",
    "hidden_B02 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_B01)\n",
    "drop_B02 = tf.keras.layers.Dropout(0.5)(hidden_B02)\n",
    "\n",
    "hidden_B03 = tf.keras.layers.Dense(32, activation = \"mish\")(drop_B02)\n",
    "# drop_B03 = tf.keras.layers.Dropout(0.5)(hidden_B03)\n",
    "\n",
    "hidden_B04 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_B03)\n",
    "drop_B04 = tf.keras.layers.Dropout(0.5)(hidden_B04)\n",
    "\n",
    "hidden_B05 = tf.keras.layers.Dense(32, activation = \"mish\")(drop_B04)\n",
    "# drop_B05 = tf.keras.layers.Dropout(0.5)(hidden_B05)\n",
    "\n",
    "hidden_B06 = tf.keras.layers.Dense(16, activation = \"mish\")(hidden_B05)\n",
    "drop_B06 = tf.keras.layers.Dropout(0.5)(hidden_B06)\n",
    "\n",
    "hidden_B07 = tf.keras.layers.Dense(16, activation = \"mish\")(drop_B06)\n",
    "# hidden_B08 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_B07)\n",
    "# drop_B08 = tf.keras.layers.Dropout(0.5)(hidden_B08)\n",
    "\n",
    "# hidden_B09 = tf.keras.layers.Dense(30, activation = \"mish\")(drop_B08)\n",
    "# hidden_B10 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_B09)\n",
    "# hidden_B11 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_B10)\n",
    "# hidden_B12 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_B11)\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "hidden_B20 = tf.keras.layers.Dense(256, activation = \"mish\")(input_B2)\n",
    "# drop_B20 = tf.keras.layers.Dropout(0.5)(hidden_B20)\n",
    "\n",
    "hidden_B21 = tf.keras.layers.Dense(64, activation = \"mish\")(hidden_B20)\n",
    "# drop_B21 = tf.keras.layers.Dropout(0.5)(hidden_B21)\n",
    "\n",
    "hidden_B22 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_B21)\n",
    "drop_B22 = tf.keras.layers.Dropout(0.5)(hidden_B22)\n",
    "\n",
    "hidden_B23 = tf.keras.layers.Dense(32, activation = \"mish\")(drop_B22)\n",
    "# drop_B23 = tf.keras.layers.Dropout(0.5)(hidden_B23)\n",
    "\n",
    "hidden_B24 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_B23)\n",
    "drop_B24 = tf.keras.layers.Dropout(0.5)(hidden_B24)\n",
    "\n",
    "hidden_B25 = tf.keras.layers.Dense(32, activation = \"mish\")(drop_B24)\n",
    "# drop_B25 = tf.keras.layers.Dropout(0.5)(hidden_B25)\n",
    "\n",
    "hidden_B26 = tf.keras.layers.Dense(16, activation = \"mish\")(hidden_B25)\n",
    "drop_B26 = tf.keras.layers.Dropout(0.5)(hidden_B26)\n",
    "\n",
    "hidden_B27 = tf.keras.layers.Dense(16, activation = \"mish\")(drop_B26)\n",
    "# hidden_B28 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_B27)\n",
    "# drop_B28 = tf.keras.layers.Dropout(0.5)(hidden_B28)\n",
    "\n",
    "# hidden_B29 = tf.keras.layers.Dense(30, activation = \"mish\")(drop_B28)\n",
    "# hidden_B30 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_B29)\n",
    "# hidden_B31 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_B30)\n",
    "# hidden_B32 = tf.keras.layers.Dense(30, activation = \"mish\")(hidden_B31)\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "hidden_C00 = tf.keras.layers.Dense(256, activation = \"mish\")(input_C1)\n",
    "# drop_C00 = tf.keras.layers.Dropout(0.5)(hidden_C00)\n",
    "\n",
    "hidden_C01 = tf.keras.layers.Dense(64, activation = \"mish\")(hidden_C00)\n",
    "# drop_C01 = tf.keras.layers.Dropout(0.5)(hidden_C01)\n",
    "\n",
    "hidden_C02 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C01)\n",
    "drop_C02 = tf.keras.layers.Dropout(0.5)(hidden_C02)\n",
    "\n",
    "hidden_C03 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C02)\n",
    "# drop_C03 = tf.keras.layers.Dropout(0.5)(hidden_C03)\n",
    "\n",
    "hidden_C04 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C03)\n",
    "drop_C04 = tf.keras.layers.Dropout(0.5)(hidden_C04)\n",
    "\n",
    "hidden_C05 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C04)\n",
    "# drop_C05 = tf.keras.layers.Dropout(0.5)(hidden_C05)\n",
    "\n",
    "hidden_C06 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C05)\n",
    "# drop_C06 = tf.keras.layers.Dropout(0.5)(hidden_C06)\n",
    "\n",
    "hidden_C07 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C06)\n",
    "# drop_C07 = tf.keras.layers.Dropout(0.5)(hidden_C07)\n",
    "hidden_C08 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C07)\n",
    "# drop_C08 = tf.keras.layers.Dropout(0.5)(hidden_C08)\n",
    "\n",
    "# hidden_C09 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C08)\n",
    "# hidden_C10 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C09)\n",
    "# hidden_C11 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C10)\n",
    "# hidden_C12 = tf.keras.layers.Dense(32, activation = \"mish\")(hidden_C11)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([hidden_A07, hidden_B07, hidden_B27, hidden_C08])\n",
    "output = tf.keras.layers.Dense(1, name = \"output\")(concat)\n",
    "model = tf.keras.Model(inputs = [input_A1, input_B1, input_B2, input_C1], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "bat_input_1 (InputLayer)        [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pit_input_1 (InputLayer)        [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pit_input_2 (InputLayer)        [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          1792        bat_input_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          2048        pit_input_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          1792        pit_input_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           16448       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           16448       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "external_factor (InputLayer)    [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           2080        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          1280        external_factor[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 64)           16448       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           1056        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           1056        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 32)           1056        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 32)           2080        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           1056        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           1056        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 32)           1056        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 32)           1056        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 32)           1056        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           1056        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           1056        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 32)           1056        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 32)           1056        dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           528         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           528         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 16)           528         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 32)           1056        dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16)           0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 32)           1056        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           272         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16)           272         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 16)           272         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 32)           1056        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80)           0           dense_7[0][0]                    \n",
      "                                                                 dense_15[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "                                                                 dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            81          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 99,345\n",
      "Trainable params: 99,345\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mae', optimizer = 'adam', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 6s 49ms/sample - loss: 5.0417 - mae: 5.0417\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 547us/sample - loss: 4.8775 - mae: 4.8775\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 555us/sample - loss: 4.5463 - mae: 4.5463\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 521us/sample - loss: 3.9284 - mae: 3.9284\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 603us/sample - loss: 2.6747 - mae: 2.6747\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 539us/sample - loss: 1.8959 - mae: 1.8959\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 527us/sample - loss: 2.2253 - mae: 2.2253\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 547us/sample - loss: 1.7581 - mae: 1.7581\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 555us/sample - loss: 1.8011 - mae: 1.8011\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 519us/sample - loss: 1.7527 - mae: 1.7527\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 547us/sample - loss: 1.6617 - mae: 1.6617\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 603us/sample - loss: 1.6568 - mae: 1.6568\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 611us/sample - loss: 1.7440 - mae: 1.7440\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 684us/sample - loss: 1.6326 - mae: 1.6326\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 587us/sample - loss: 1.6203 - mae: 1.6203\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 651us/sample - loss: 1.6797 - mae: 1.6797\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 756us/sample - loss: 1.6297 - mae: 1.6297\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 627us/sample - loss: 1.5723 - mae: 1.5723\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 660us/sample - loss: 1.6267 - mae: 1.6267\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 611us/sample - loss: 1.6162 - mae: 1.6162\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 708us/sample - loss: 1.5547 - mae: 1.5547\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 696us/sample - loss: 1.5948 - mae: 1.5948\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 700us/sample - loss: 1.6385 - mae: 1.6385\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 563us/sample - loss: 1.6558 - mae: 1.6558\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 571us/sample - loss: 1.5675 - mae: 1.5675\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 587us/sample - loss: 1.5848 - mae: 1.5848\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 531us/sample - loss: 1.6302 - mae: 1.6302\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 540us/sample - loss: 1.5914 - mae: 1.5914\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 563us/sample - loss: 1.5383 - mae: 1.5383\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 540us/sample - loss: 1.5909 - mae: 1.5909\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 547us/sample - loss: 1.5621 - mae: 1.5621\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 539us/sample - loss: 1.6003 - mae: 1.6003\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 595us/sample - loss: 1.5786 - mae: 1.5786\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 627us/sample - loss: 1.5814 - mae: 1.5814\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 539us/sample - loss: 1.5643 - mae: 1.5643\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 619us/sample - loss: 1.5846 - mae: 1.5846\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 579us/sample - loss: 1.5829 - mae: 1.5829\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 531us/sample - loss: 1.5660 - mae: 1.5660\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 539us/sample - loss: 1.5483 - mae: 1.5483\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 547us/sample - loss: 1.5163 - mae: 1.5163\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 628us/sample - loss: 1.5255 - mae: 1.5255\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 764us/sample - loss: 1.5865 - mae: 1.5865\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 812us/sample - loss: 1.4944 - mae: 1.4944\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 941us/sample - loss: 1.4684 - mae: 1.4684\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 579us/sample - loss: 1.5811 - mae: 1.5811\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 579us/sample - loss: 1.5024 - mae: 1.5024\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 528us/sample - loss: 1.4680 - mae: 1.4680\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 547us/sample - loss: 1.5518 - mae: 1.5518\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 539us/sample - loss: 1.5442 - mae: 1.5442\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 597us/sample - loss: 1.5201 - mae: 1.5201\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([input_a1, input_b1, input_b2, input_c1], [Output], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict((tinput_a1, tinput_b1, tinput_b2, tinput_c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 5ms/sample - loss: 1.4693 - mae: 1.4693\n"
     ]
    }
   ],
   "source": [
    "test = model.evaluate((input_a1, input_b1, input_b2, input_c1), (Output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "31/31 [==============================] - 0s 322us/sample - loss: 1.6142 - mae: 1.6142\n"
     ]
    }
   ],
   "source": [
    "test = model.evaluate((tinput_a1, tinput_b1, tinput_b2, tinput_c1), (y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(y))\n",
    "y = y\n",
    "y2 = pred\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.plot(x, y,'x', label = 'real')\n",
    "plt.plot(x, y2, 'o', label = 'predict')\n",
    "plt.xlabel('game')\n",
    "plt.ylabel('RUN')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
